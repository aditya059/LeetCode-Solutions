// C++
class Solution {
    int setBitCount(int n) {
        int count = 0;
        while(n) {
            n -= (n & -n);
            count++;
        }
        return count;
    }
public:
    int maximumRows(vector<vector<int>>& matrix, int numSelect) {
        int m = matrix.size();
        int n = matrix[0].size();
        vector<int> decimal(m, 0);
        for(int i = 0; i < m; i++) {
            for(int j = 0; j < n; j++) {
                decimal[i] = decimal[i] * 2 + matrix[i][j];
            }
        }
        int k = 1 << n, ans = 0;
        for(int i = 0; i < k; i++) {
            if(setBitCount(i) != numSelect) continue;
            int val = k - i - 1, count = 0;
            for(int j = 0; j < m; j++) {
                count += !(val & decimal[j]);
            }
            ans = max(ans, count);
        }
        return ans;
    }
};


// Golang
func setBitCount(n int) int {
    var count int = 0
    for n > 0 {
        n -= (n & -n)
        count++
    }
    return count
}

func maximumRows(matrix [][]int, numSelect int) int {
    var m int = len(matrix)
    var n int = len(matrix[0])
    decimal := make([]int, m)
    for i := 0; i < m; i++ {
        for j := 0; j < n; j++ {
            decimal[i] = decimal[i] * 2 + matrix[i][j]
        }
    }
    var k, ans int = 1 << n, 0
    for i := 0; i < k; i++ {
        if setBitCount(i) != numSelect {continue}
        var val, count int = k - i - 1, 0
        for j := 0; j < m; j++ {
            if val & decimal[j] == 0 {
                count++
            }
        }
        if count > ans {
            ans = count
        }
    }
    return ans
}
